{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1060e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c4412d",
   "metadata": {},
   "source": [
    "## Data preprocessing for given dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f618bc69",
   "metadata": {},
   "source": [
    "## 1. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d92064",
   "metadata": {},
   "source": [
    "### 1.1. Importing data and providing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6bb0fa2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close(t)</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SD20</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>S_Close(t-1)</th>\n",
       "      <th>...</th>\n",
       "      <th>QQQ_MA10</th>\n",
       "      <th>QQQ_MA20</th>\n",
       "      <th>QQQ_MA50</th>\n",
       "      <th>SnP_Close</th>\n",
       "      <th>SnP(t-1))</th>\n",
       "      <th>SnP(t-5)</th>\n",
       "      <th>DJIA_Close</th>\n",
       "      <th>DJIA(t-1))</th>\n",
       "      <th>DJIA(t-5)</th>\n",
       "      <th>Close_forcast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-10-18</td>\n",
       "      <td>165.00</td>\n",
       "      <td>165.19</td>\n",
       "      <td>161.82</td>\n",
       "      <td>163.56</td>\n",
       "      <td>6331300</td>\n",
       "      <td>3.770297</td>\n",
       "      <td>164.383594</td>\n",
       "      <td>149.302406</td>\n",
       "      <td>164.64</td>\n",
       "      <td>...</td>\n",
       "      <td>45.335</td>\n",
       "      <td>44.8280</td>\n",
       "      <td>42.6302</td>\n",
       "      <td>1184.71</td>\n",
       "      <td>1176.19</td>\n",
       "      <td>1165.32</td>\n",
       "      <td>11143.69</td>\n",
       "      <td>11062.78</td>\n",
       "      <td>11010.34</td>\n",
       "      <td>158.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-10-19</td>\n",
       "      <td>160.68</td>\n",
       "      <td>162.80</td>\n",
       "      <td>157.00</td>\n",
       "      <td>158.67</td>\n",
       "      <td>7525000</td>\n",
       "      <td>3.501162</td>\n",
       "      <td>164.242324</td>\n",
       "      <td>150.237676</td>\n",
       "      <td>163.56</td>\n",
       "      <td>...</td>\n",
       "      <td>45.440</td>\n",
       "      <td>44.9185</td>\n",
       "      <td>42.6998</td>\n",
       "      <td>1165.90</td>\n",
       "      <td>1184.71</td>\n",
       "      <td>1169.77</td>\n",
       "      <td>10978.62</td>\n",
       "      <td>11143.69</td>\n",
       "      <td>11020.40</td>\n",
       "      <td>158.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-10-20</td>\n",
       "      <td>158.78</td>\n",
       "      <td>159.87</td>\n",
       "      <td>156.57</td>\n",
       "      <td>158.67</td>\n",
       "      <td>5790400</td>\n",
       "      <td>3.271424</td>\n",
       "      <td>164.124849</td>\n",
       "      <td>151.039151</td>\n",
       "      <td>158.67</td>\n",
       "      <td>...</td>\n",
       "      <td>45.617</td>\n",
       "      <td>45.0315</td>\n",
       "      <td>42.7834</td>\n",
       "      <td>1178.17</td>\n",
       "      <td>1165.90</td>\n",
       "      <td>1178.10</td>\n",
       "      <td>11107.97</td>\n",
       "      <td>10978.62</td>\n",
       "      <td>11096.08</td>\n",
       "      <td>164.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-10-21</td>\n",
       "      <td>162.67</td>\n",
       "      <td>166.13</td>\n",
       "      <td>161.29</td>\n",
       "      <td>164.97</td>\n",
       "      <td>13482500</td>\n",
       "      <td>3.465530</td>\n",
       "      <td>165.119061</td>\n",
       "      <td>151.256939</td>\n",
       "      <td>158.67</td>\n",
       "      <td>...</td>\n",
       "      <td>45.787</td>\n",
       "      <td>45.1500</td>\n",
       "      <td>42.8918</td>\n",
       "      <td>1180.26</td>\n",
       "      <td>1178.17</td>\n",
       "      <td>1173.81</td>\n",
       "      <td>11146.57</td>\n",
       "      <td>11107.97</td>\n",
       "      <td>11094.57</td>\n",
       "      <td>169.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-10-22</td>\n",
       "      <td>162.45</td>\n",
       "      <td>170.17</td>\n",
       "      <td>162.27</td>\n",
       "      <td>169.13</td>\n",
       "      <td>16318400</td>\n",
       "      <td>4.217293</td>\n",
       "      <td>167.042587</td>\n",
       "      <td>150.173413</td>\n",
       "      <td>164.97</td>\n",
       "      <td>...</td>\n",
       "      <td>45.958</td>\n",
       "      <td>45.2395</td>\n",
       "      <td>43.0130</td>\n",
       "      <td>1183.08</td>\n",
       "      <td>1180.26</td>\n",
       "      <td>1176.19</td>\n",
       "      <td>11132.56</td>\n",
       "      <td>11146.57</td>\n",
       "      <td>11062.78</td>\n",
       "      <td>169.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open    High     Low  Close(t)    Volume      SD20  \\\n",
       "0  2010-10-18  165.00  165.19  161.82    163.56   6331300  3.770297   \n",
       "1  2010-10-19  160.68  162.80  157.00    158.67   7525000  3.501162   \n",
       "2  2010-10-20  158.78  159.87  156.57    158.67   5790400  3.271424   \n",
       "3  2010-10-21  162.67  166.13  161.29    164.97  13482500  3.465530   \n",
       "4  2010-10-22  162.45  170.17  162.27    169.13  16318400  4.217293   \n",
       "\n",
       "   Upper_Band  Lower_Band  S_Close(t-1)  ...  QQQ_MA10  QQQ_MA20  QQQ_MA50  \\\n",
       "0  164.383594  149.302406        164.64  ...    45.335   44.8280   42.6302   \n",
       "1  164.242324  150.237676        163.56  ...    45.440   44.9185   42.6998   \n",
       "2  164.124849  151.039151        158.67  ...    45.617   45.0315   42.7834   \n",
       "3  165.119061  151.256939        158.67  ...    45.787   45.1500   42.8918   \n",
       "4  167.042587  150.173413        164.97  ...    45.958   45.2395   43.0130   \n",
       "\n",
       "   SnP_Close  SnP(t-1))  SnP(t-5)  DJIA_Close  DJIA(t-1))  DJIA(t-5)  \\\n",
       "0    1184.71    1176.19   1165.32    11143.69    11062.78   11010.34   \n",
       "1    1165.90    1184.71   1169.77    10978.62    11143.69   11020.40   \n",
       "2    1178.17    1165.90   1178.10    11107.97    10978.62   11096.08   \n",
       "3    1180.26    1178.17   1173.81    11146.57    11107.97   11094.57   \n",
       "4    1183.08    1180.26   1176.19    11132.56    11146.57   11062.78   \n",
       "\n",
       "   Close_forcast  \n",
       "0         158.67  \n",
       "1         158.67  \n",
       "2         164.97  \n",
       "3         169.13  \n",
       "4         169.00  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('AMZN.csv')\n",
    "# fb=pd.read_csv('FB.csv')\n",
    "# gg=pd.read_csv('GOOGL.csv')\n",
    "# ibm=pd.read_csv('IBM.csv')\n",
    "# msf=pd.read_csv('MSFT.csv')\n",
    "# df=pd.concat([msf,gg ,ibm ,fb ,amz], axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ed8a58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2473 entries, 0 to 2472\n",
      "Data columns (total 64 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Date              2473 non-null   object \n",
      " 1   Open              2473 non-null   float64\n",
      " 2   High              2473 non-null   float64\n",
      " 3   Low               2473 non-null   float64\n",
      " 4   Close(t)          2473 non-null   float64\n",
      " 5   Volume            2473 non-null   int64  \n",
      " 6   SD20              2473 non-null   float64\n",
      " 7   Upper_Band        2473 non-null   float64\n",
      " 8   Lower_Band        2473 non-null   float64\n",
      " 9   S_Close(t-1)      2473 non-null   float64\n",
      " 10  S_Close(t-2)      2473 non-null   float64\n",
      " 11  S_Close(t-3)      2473 non-null   float64\n",
      " 12  S_Close(t-5)      2473 non-null   float64\n",
      " 13  S_Open(t-1)       2473 non-null   float64\n",
      " 14  MA5               2473 non-null   float64\n",
      " 15  MA10              2473 non-null   float64\n",
      " 16  MA20              2473 non-null   float64\n",
      " 17  MA50              2473 non-null   float64\n",
      " 18  MA200             2473 non-null   float64\n",
      " 19  EMA10             2473 non-null   float64\n",
      " 20  EMA20             2473 non-null   float64\n",
      " 21  EMA50             2473 non-null   float64\n",
      " 22  EMA100            2473 non-null   float64\n",
      " 23  EMA200            2473 non-null   float64\n",
      " 24  MACD              2473 non-null   float64\n",
      " 25  MACD_EMA          2473 non-null   float64\n",
      " 26  ATR               2473 non-null   float64\n",
      " 27  ADX               2473 non-null   float64\n",
      " 28  CCI               2473 non-null   float64\n",
      " 29  ROC               2473 non-null   float64\n",
      " 30  RSI               2473 non-null   float64\n",
      " 31  William%R         2473 non-null   float64\n",
      " 32  SO%K              2473 non-null   float64\n",
      " 33  STD5              2473 non-null   float64\n",
      " 34  ForceIndex1       2473 non-null   float64\n",
      " 35  ForceIndex20      2473 non-null   float64\n",
      " 36  Date_col          2473 non-null   object \n",
      " 37  Day               2473 non-null   int64  \n",
      " 38  DayofWeek         2473 non-null   int64  \n",
      " 39  DayofYear         2473 non-null   int64  \n",
      " 40  Week              2473 non-null   int64  \n",
      " 41  Is_month_end      2473 non-null   int64  \n",
      " 42  Is_month_start    2473 non-null   int64  \n",
      " 43  Is_quarter_end    2473 non-null   int64  \n",
      " 44  Is_quarter_start  2473 non-null   int64  \n",
      " 45  Is_year_end       2473 non-null   int64  \n",
      " 46  Is_year_start     2473 non-null   int64  \n",
      " 47  Is_leap_year      2473 non-null   int64  \n",
      " 48  Year              2473 non-null   int64  \n",
      " 49  Month             2473 non-null   int64  \n",
      " 50  QQQ_Close         2473 non-null   float64\n",
      " 51  QQQ(t-1)          2473 non-null   float64\n",
      " 52  QQQ(t-2)          2473 non-null   float64\n",
      " 53  QQQ(t-5)          2473 non-null   float64\n",
      " 54  QQQ_MA10          2473 non-null   float64\n",
      " 55  QQQ_MA20          2473 non-null   float64\n",
      " 56  QQQ_MA50          2473 non-null   float64\n",
      " 57  SnP_Close         2473 non-null   float64\n",
      " 58  SnP(t-1))         2473 non-null   float64\n",
      " 59  SnP(t-5)          2473 non-null   float64\n",
      " 60  DJIA_Close        2473 non-null   float64\n",
      " 61  DJIA(t-1))        2473 non-null   float64\n",
      " 62  DJIA(t-5)         2473 non-null   float64\n",
      " 63  Close_forcast     2473 non-null   float64\n",
      "dtypes: float64(48), int64(14), object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7da71a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close(t)</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SD20</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>S_Close(t-1)</th>\n",
       "      <th>S_Close(t-2)</th>\n",
       "      <th>...</th>\n",
       "      <th>QQQ_MA10</th>\n",
       "      <th>QQQ_MA20</th>\n",
       "      <th>QQQ_MA50</th>\n",
       "      <th>SnP_Close</th>\n",
       "      <th>SnP(t-1))</th>\n",
       "      <th>SnP(t-5)</th>\n",
       "      <th>DJIA_Close</th>\n",
       "      <th>DJIA(t-1))</th>\n",
       "      <th>DJIA(t-5)</th>\n",
       "      <th>Close_forcast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2.473000e+03</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "      <td>2473.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>826.164590</td>\n",
       "      <td>834.746130</td>\n",
       "      <td>816.663631</td>\n",
       "      <td>826.197849</td>\n",
       "      <td>4.309489e+06</td>\n",
       "      <td>25.257533</td>\n",
       "      <td>865.297646</td>\n",
       "      <td>764.267514</td>\n",
       "      <td>824.986211</td>\n",
       "      <td>823.770396</td>\n",
       "      <td>...</td>\n",
       "      <td>113.401112</td>\n",
       "      <td>112.954962</td>\n",
       "      <td>111.653683</td>\n",
       "      <td>2098.568795</td>\n",
       "      <td>2097.680303</td>\n",
       "      <td>2094.146624</td>\n",
       "      <td>18694.046041</td>\n",
       "      <td>18687.238949</td>\n",
       "      <td>18660.280890</td>\n",
       "      <td>827.404666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>698.038503</td>\n",
       "      <td>705.987111</td>\n",
       "      <td>689.294489</td>\n",
       "      <td>698.082871</td>\n",
       "      <td>2.417880e+06</td>\n",
       "      <td>29.641950</td>\n",
       "      <td>730.285700</td>\n",
       "      <td>638.652752</td>\n",
       "      <td>696.627602</td>\n",
       "      <td>695.169032</td>\n",
       "      <td>...</td>\n",
       "      <td>52.643302</td>\n",
       "      <td>52.248810</td>\n",
       "      <td>51.174082</td>\n",
       "      <td>596.210304</td>\n",
       "      <td>595.946837</td>\n",
       "      <td>594.947984</td>\n",
       "      <td>5129.355628</td>\n",
       "      <td>5128.307884</td>\n",
       "      <td>5124.540611</td>\n",
       "      <td>699.515103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>157.840000</td>\n",
       "      <td>159.870000</td>\n",
       "      <td>156.570000</td>\n",
       "      <td>157.780000</td>\n",
       "      <td>8.813000e+05</td>\n",
       "      <td>2.454017</td>\n",
       "      <td>164.124849</td>\n",
       "      <td>148.681227</td>\n",
       "      <td>157.780000</td>\n",
       "      <td>155.530000</td>\n",
       "      <td>...</td>\n",
       "      <td>45.335000</td>\n",
       "      <td>44.828000</td>\n",
       "      <td>42.630200</td>\n",
       "      <td>1099.230000</td>\n",
       "      <td>1099.230000</td>\n",
       "      <td>1099.230000</td>\n",
       "      <td>10655.300000</td>\n",
       "      <td>10655.300000</td>\n",
       "      <td>10655.300000</td>\n",
       "      <td>157.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>266.810000</td>\n",
       "      <td>269.480000</td>\n",
       "      <td>263.850000</td>\n",
       "      <td>266.490000</td>\n",
       "      <td>2.755800e+06</td>\n",
       "      <td>6.951115</td>\n",
       "      <td>277.869989</td>\n",
       "      <td>253.212633</td>\n",
       "      <td>266.410000</td>\n",
       "      <td>266.380000</td>\n",
       "      <td>...</td>\n",
       "      <td>63.835000</td>\n",
       "      <td>63.633500</td>\n",
       "      <td>62.854000</td>\n",
       "      <td>1562.170000</td>\n",
       "      <td>1560.700000</td>\n",
       "      <td>1556.220000</td>\n",
       "      <td>14567.170000</td>\n",
       "      <td>14565.250000</td>\n",
       "      <td>14539.140000</td>\n",
       "      <td>266.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>528.520000</td>\n",
       "      <td>534.560000</td>\n",
       "      <td>521.400000</td>\n",
       "      <td>529.420000</td>\n",
       "      <td>3.686200e+06</td>\n",
       "      <td>13.908356</td>\n",
       "      <td>558.160917</td>\n",
       "      <td>472.483684</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>527.460000</td>\n",
       "      <td>...</td>\n",
       "      <td>102.697000</td>\n",
       "      <td>102.748500</td>\n",
       "      <td>102.633400</td>\n",
       "      <td>2067.030000</td>\n",
       "      <td>2066.960000</td>\n",
       "      <td>2066.130000</td>\n",
       "      <td>17716.050000</td>\n",
       "      <td>17712.660000</td>\n",
       "      <td>17705.910000</td>\n",
       "      <td>529.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1445.000000</td>\n",
       "      <td>1459.780000</td>\n",
       "      <td>1415.020000</td>\n",
       "      <td>1442.840000</td>\n",
       "      <td>5.070300e+06</td>\n",
       "      <td>31.115370</td>\n",
       "      <td>1552.733137</td>\n",
       "      <td>1334.556935</td>\n",
       "      <td>1441.500000</td>\n",
       "      <td>1437.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>157.845000</td>\n",
       "      <td>157.894500</td>\n",
       "      <td>158.643600</td>\n",
       "      <td>2639.440000</td>\n",
       "      <td>2639.400000</td>\n",
       "      <td>2636.780000</td>\n",
       "      <td>23924.980000</td>\n",
       "      <td>23909.840000</td>\n",
       "      <td>23860.460000</td>\n",
       "      <td>1447.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3251.060000</td>\n",
       "      <td>3344.290000</td>\n",
       "      <td>3165.430000</td>\n",
       "      <td>3225.000000</td>\n",
       "      <td>2.413420e+07</td>\n",
       "      <td>205.254540</td>\n",
       "      <td>3321.751870</td>\n",
       "      <td>2948.254283</td>\n",
       "      <td>3225.000000</td>\n",
       "      <td>3225.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>270.255000</td>\n",
       "      <td>265.454000</td>\n",
       "      <td>255.044600</td>\n",
       "      <td>3386.150000</td>\n",
       "      <td>3386.150000</td>\n",
       "      <td>3386.150000</td>\n",
       "      <td>29551.420000</td>\n",
       "      <td>29551.420000</td>\n",
       "      <td>29551.420000</td>\n",
       "      <td>3225.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low     Close(t)        Volume  \\\n",
       "count  2473.000000  2473.000000  2473.000000  2473.000000  2.473000e+03   \n",
       "mean    826.164590   834.746130   816.663631   826.197849  4.309489e+06   \n",
       "std     698.038503   705.987111   689.294489   698.082871  2.417880e+06   \n",
       "min     157.840000   159.870000   156.570000   157.780000  8.813000e+05   \n",
       "25%     266.810000   269.480000   263.850000   266.490000  2.755800e+06   \n",
       "50%     528.520000   534.560000   521.400000   529.420000  3.686200e+06   \n",
       "75%    1445.000000  1459.780000  1415.020000  1442.840000  5.070300e+06   \n",
       "max    3251.060000  3344.290000  3165.430000  3225.000000  2.413420e+07   \n",
       "\n",
       "              SD20   Upper_Band   Lower_Band  S_Close(t-1)  S_Close(t-2)  ...  \\\n",
       "count  2473.000000  2473.000000  2473.000000   2473.000000   2473.000000  ...   \n",
       "mean     25.257533   865.297646   764.267514    824.986211    823.770396  ...   \n",
       "std      29.641950   730.285700   638.652752    696.627602    695.169032  ...   \n",
       "min       2.454017   164.124849   148.681227    157.780000    155.530000  ...   \n",
       "25%       6.951115   277.869989   253.212633    266.410000    266.380000  ...   \n",
       "50%      13.908356   558.160917   472.483684    529.000000    527.460000  ...   \n",
       "75%      31.115370  1552.733137  1334.556935   1441.500000   1437.820000  ...   \n",
       "max     205.254540  3321.751870  2948.254283   3225.000000   3225.000000  ...   \n",
       "\n",
       "          QQQ_MA10     QQQ_MA20     QQQ_MA50    SnP_Close    SnP(t-1))  \\\n",
       "count  2473.000000  2473.000000  2473.000000  2473.000000  2473.000000   \n",
       "mean    113.401112   112.954962   111.653683  2098.568795  2097.680303   \n",
       "std      52.643302    52.248810    51.174082   596.210304   595.946837   \n",
       "min      45.335000    44.828000    42.630200  1099.230000  1099.230000   \n",
       "25%      63.835000    63.633500    62.854000  1562.170000  1560.700000   \n",
       "50%     102.697000   102.748500   102.633400  2067.030000  2066.960000   \n",
       "75%     157.845000   157.894500   158.643600  2639.440000  2639.400000   \n",
       "max     270.255000   265.454000   255.044600  3386.150000  3386.150000   \n",
       "\n",
       "          SnP(t-5)    DJIA_Close    DJIA(t-1))     DJIA(t-5)  Close_forcast  \n",
       "count  2473.000000   2473.000000   2473.000000   2473.000000    2473.000000  \n",
       "mean   2094.146624  18694.046041  18687.238949  18660.280890     827.404666  \n",
       "std     594.947984   5129.355628   5128.307884   5124.540611     699.515103  \n",
       "min    1099.230000  10655.300000  10655.300000  10655.300000     157.780000  \n",
       "25%    1556.220000  14567.170000  14565.250000  14539.140000     266.560000  \n",
       "50%    2066.130000  17716.050000  17712.660000  17705.910000     529.440000  \n",
       "75%    2636.780000  23924.980000  23909.840000  23860.460000    1447.340000  \n",
       "max    3386.150000  29551.420000  29551.420000  29551.420000    3225.000000  \n",
       "\n",
       "[8 rows x 62 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ddac20e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close(t)', 'Volume', 'SD20',\n",
       "       'Upper_Band', 'Lower_Band', 'S_Close(t-1)', 'S_Close(t-2)',\n",
       "       'S_Close(t-3)', 'S_Close(t-5)', 'S_Open(t-1)', 'MA5', 'MA10', 'MA20',\n",
       "       'MA50', 'MA200', 'EMA10', 'EMA20', 'EMA50', 'EMA100', 'EMA200', 'MACD',\n",
       "       'MACD_EMA', 'ATR', 'ADX', 'CCI', 'ROC', 'RSI', 'William%R', 'SO%K',\n",
       "       'STD5', 'ForceIndex1', 'ForceIndex20', 'Date_col', 'Day', 'DayofWeek',\n",
       "       'DayofYear', 'Week', 'Is_month_end', 'Is_month_start', 'Is_quarter_end',\n",
       "       'Is_quarter_start', 'Is_year_end', 'Is_year_start', 'Is_leap_year',\n",
       "       'Year', 'Month', 'QQQ_Close', 'QQQ(t-1)', 'QQQ(t-2)', 'QQQ(t-5)',\n",
       "       'QQQ_MA10', 'QQQ_MA20', 'QQQ_MA50', 'SnP_Close', 'SnP(t-1))',\n",
       "       'SnP(t-5)', 'DJIA_Close', 'DJIA(t-1))', 'DJIA(t-5)', 'Close_forcast'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936240ff",
   "metadata": {},
   "source": [
    "### 1.2. Handling null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "994b4606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values detected.\n"
     ]
    }
   ],
   "source": [
    "df.isnull().any().any()\n",
    "print(\"No null values detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c435f97",
   "metadata": {},
   "source": [
    "## 2. Data manupulation and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0759e58",
   "metadata": {},
   "source": [
    "### 2.1. Creating new trend column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c5af501",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>2010-10-18</td>\n",
       "      <td>2010-10-19</td>\n",
       "      <td>2010-10-20</td>\n",
       "      <td>2010-10-21</td>\n",
       "      <td>2010-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>165.0</td>\n",
       "      <td>160.68</td>\n",
       "      <td>158.78</td>\n",
       "      <td>162.67</td>\n",
       "      <td>162.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>165.19</td>\n",
       "      <td>162.8</td>\n",
       "      <td>159.87</td>\n",
       "      <td>166.13</td>\n",
       "      <td>170.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>161.82</td>\n",
       "      <td>157.0</td>\n",
       "      <td>156.57</td>\n",
       "      <td>161.29</td>\n",
       "      <td>162.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close(t)</th>\n",
       "      <td>163.56</td>\n",
       "      <td>158.67</td>\n",
       "      <td>158.67</td>\n",
       "      <td>164.97</td>\n",
       "      <td>169.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DJIA(t-1))</th>\n",
       "      <td>11062.78</td>\n",
       "      <td>11143.69</td>\n",
       "      <td>10978.62</td>\n",
       "      <td>11107.97</td>\n",
       "      <td>11146.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DJIA(t-5)</th>\n",
       "      <td>11010.34</td>\n",
       "      <td>11020.4</td>\n",
       "      <td>11096.08</td>\n",
       "      <td>11094.57</td>\n",
       "      <td>11062.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_forcast</th>\n",
       "      <td>158.67</td>\n",
       "      <td>158.67</td>\n",
       "      <td>164.97</td>\n",
       "      <td>169.13</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stock Price Difference</th>\n",
       "      <td>1.44</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-6.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trend</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0           1           2           3  \\\n",
       "Date                    2010-10-18  2010-10-19  2010-10-20  2010-10-21   \n",
       "Open                         165.0      160.68      158.78      162.67   \n",
       "High                        165.19       162.8      159.87      166.13   \n",
       "Low                         161.82       157.0      156.57      161.29   \n",
       "Close(t)                    163.56      158.67      158.67      164.97   \n",
       "...                            ...         ...         ...         ...   \n",
       "DJIA(t-1))                11062.78    11143.69    10978.62    11107.97   \n",
       "DJIA(t-5)                 11010.34     11020.4    11096.08    11094.57   \n",
       "Close_forcast               158.67      158.67      164.97      169.13   \n",
       "Stock Price Difference        1.44        2.01        0.11        -2.3   \n",
       "Trend                            1           1           1           2   \n",
       "\n",
       "                                 4  \n",
       "Date                    2010-10-22  \n",
       "Open                        162.45  \n",
       "High                        170.17  \n",
       "Low                         162.27  \n",
       "Close(t)                    169.13  \n",
       "...                            ...  \n",
       "DJIA(t-1))                11146.57  \n",
       "DJIA(t-5)                 11062.78  \n",
       "Close_forcast                169.0  \n",
       "Stock Price Difference       -6.68  \n",
       "Trend                            2  \n",
       "\n",
       "[66 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, open is the previous stock price and close(t) is the current\n",
    "# stock price\n",
    "\n",
    "# Subtracting the stock prices we get the trend of stock going up (1)\n",
    "# or down(0)\n",
    "\n",
    "df['Stock Price Difference'] = df['Open'] - df['Close(t)']\n",
    "def assign_category(value):\n",
    "    if value > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2 # no 0 value, so value=0 not taken\n",
    "\n",
    "df['Trend'] = df['Stock Price Difference'].apply(assign_category)\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd02fc1e",
   "metadata": {},
   "source": [
    "### 2.2. Dropping irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d316885",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:64] #independent columns\n",
    "cols = [0, 36, 63]\n",
    "X.drop(X.columns[cols], axis=1, inplace=True)\n",
    "y=df.iloc[:,-1] #target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8a65d68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler=StandardScaler()\n",
    "#X=scaler.fit_transform(X)\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e3c1e",
   "metadata": {},
   "source": [
    "### 2.3. Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa15e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = zscore(X)\n",
    "data_no_outliers = X[(np.abs(z_scores) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95338da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No outliers detected.\n"
     ]
    }
   ],
   "source": [
    "if data_no_outliers.empty:\n",
    "    print(\"\\nNo outliers detected.\")\n",
    "else:\n",
    "    print(\"\\nData without outliers:\")\n",
    "    print(data_no_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9631fa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2473, 61)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8db0b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2473,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc256477",
   "metadata": {},
   "source": [
    "## 3. Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f09e873",
   "metadata": {},
   "source": [
    "### 3.1. Scaling the given features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e8debf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling all the features and the target variable as well\n",
    "scaler_features = StandardScaler()\n",
    "scaler_target = StandardScaler()\n",
    "\n",
    "X_scaled = scaler_features.fit_transform(X)\n",
    "y_scaled = scaler_target.fit_transform(y.values.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab53c12",
   "metadata": {},
   "source": [
    "## 4. Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "596a2557",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=26)\n",
    "\n",
    "# Creating a model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Training the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2705abc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7232323232323232\n",
      "Confusion Matrix:\n",
      " [[166  63]\n",
      " [ 74 192]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.72      0.71       229\n",
      "           2       0.75      0.72      0.74       266\n",
      "\n",
      "    accuracy                           0.72       495\n",
      "   macro avg       0.72      0.72      0.72       495\n",
      "weighted avg       0.72      0.72      0.72       495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=26)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Creating a classification model (Logistic Regression)\n",
    "classifier = LogisticRegression(random_state=26,max_iter=3000)\n",
    "\n",
    "# Training the model on the training set\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a06791",
   "metadata": {},
   "source": [
    "## 5. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca6ee3",
   "metadata": {},
   "source": [
    "### 5.1. Using Extra Trees Classifier for shortlisting important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcb72142-2aae-41d8-aba8-fb7743471a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(random_state=12)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(random_state=12)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(random_state=12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ExtraTreesClassifier(random_state=12)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "925ec953-015a-4e4a-b15d-bf53cf3fc43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01898862 0.01282987 0.01291171 0.01397721 0.02080691 0.0168999\n",
      " 0.01276601 0.01239969 0.01769267 0.01468048 0.01399332 0.01340021\n",
      " 0.01403333 0.01190485 0.01243912 0.01142794 0.01170902 0.01066432\n",
      " 0.01197652 0.01116913 0.01120003 0.01214246 0.01108223 0.018467\n",
      " 0.01600756 0.01527202 0.01821493 0.         0.02319901 0.02876765\n",
      " 0.07667346 0.08271431 0.0203477  0.09885334 0.01861131 0.01785034\n",
      " 0.02422058 0.01435991 0.01195701 0.00375791 0.00392464 0.0014107\n",
      " 0.00128641 0.00052007 0.         0.00360317 0.00478043 0.0098668\n",
      " 0.01349961 0.01443965 0.01322792 0.01278947 0.01195558 0.01117872\n",
      " 0.01114092 0.0136354  0.01447293 0.01462931 0.01404789 0.01509856\n",
      " 0.01412225]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62e7a87c-6d61-4255-a032-29e82ac088c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f8198",
   "metadata": {},
   "source": [
    "### 5.2. Revealing features with highest importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb7a0d2d-8f43-4fda-a452-cc5fc39bb4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['MACD','Volume','STD5','Day','DayofWeek','ROC','RSI','SO%K',\n",
    "       'ForceIndex1','William%R','SD20','S_Close(t-1)','ADX',\n",
    "        'ForceIndex20','Open']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f59a9181-178e-418a-935c-3f6e0b554d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2473 entries, 0 to 2472\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   MACD          2473 non-null   float64\n",
      " 1   Volume        2473 non-null   int64  \n",
      " 2   STD5          2473 non-null   float64\n",
      " 3   Day           2473 non-null   int64  \n",
      " 4   DayofWeek     2473 non-null   int64  \n",
      " 5   ROC           2473 non-null   float64\n",
      " 6   RSI           2473 non-null   float64\n",
      " 7   SO%K          2473 non-null   float64\n",
      " 8   ForceIndex1   2473 non-null   float64\n",
      " 9   William%R     2473 non-null   float64\n",
      " 10  SD20          2473 non-null   float64\n",
      " 11  S_Close(t-1)  2473 non-null   float64\n",
      " 12  ADX           2473 non-null   float64\n",
      " 13  ForceIndex20  2473 non-null   float64\n",
      " 14  Open          2473 non-null   float64\n",
      "dtypes: float64(12), int64(3)\n",
      "memory usage: 289.9 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f74be4d",
   "metadata": {},
   "source": [
    "## 6. Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d06cb2",
   "metadata": {},
   "source": [
    "### 6.1. Scaling and splitting the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f43d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1712947f",
   "metadata": {},
   "source": [
    "### 6.2. Logistic Regression for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5543cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression(max_iter=1000) ##max no. of iterations reached ,so 1000 used\n",
    "logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7a43007-3935-47c1-b7d2-0a2a0f1964a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0c869a2-026a-491d-9ddf-ee5c8bf6b43d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.81      0.83       253\n",
      "           2       0.81      0.85      0.83       242\n",
      "\n",
      "    accuracy                           0.83       495\n",
      "   macro avg       0.83      0.83      0.83       495\n",
      "weighted avg       0.83      0.83      0.83       495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfbc176",
   "metadata": {},
   "source": [
    "## 7. Scaling and splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9639e83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_train = y_train.values.reshape(-1,1)\n",
    "y_test = y_test.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd199c",
   "metadata": {},
   "source": [
    "## 8. Using Sigmoid activation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec1723de-6989-4596-9fd8-0b8fcf6e33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two functions - the sigmoid activation function and its derivative\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f127f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train_scaled.shape[1]\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "weights = np.random.randn(input_size, output_size)\n",
    "bias = np.zeros((1, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42016320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 1.4713799077100609\n",
      "Iteration 100, Loss: 0.2309987835459459\n",
      "Iteration 200, Loss: -0.5637085356426342\n",
      "Iteration 300, Loss: -1.1236187811934528\n",
      "Iteration 400, Loss: -1.568363150618599\n",
      "Iteration 500, Loss: -1.9544015268409094\n",
      "Iteration 600, Loss: -2.309558978940539\n",
      "Iteration 700, Loss: -2.647893724408783\n",
      "Iteration 800, Loss: -2.9760227868220372\n",
      "Iteration 900, Loss: -3.297805221678526\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 1000\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # Forward pass\n",
    "    z = np.dot(X_train_scaled, weights) + bias\n",
    "    a = sigmoid(z)\n",
    "\n",
    "    # Compute loss (log loss)\n",
    "    epsilon = 1e-8\n",
    "    loss = -np.mean(y_train * np.log(a + epsilon) + (1 - y_train) * np.log(1 - a + epsilon))\n",
    "\n",
    "    # Backpropagation\n",
    "    dz = a - y_train.reshape(-1, 1)\n",
    "    dw = np.dot(X_train_scaled.T, dz) / len(X_train_scaled)\n",
    "    db = np.sum(dz) / len(X_train_scaled)\n",
    "\n",
    "    # Update weights and bias\n",
    "    weights -= learning_rate * dw\n",
    "    bias -= learning_rate * db\n",
    "\n",
    "    # Print the loss for every 100 iterations\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89b87b5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46464646464646464\n",
      "Log Loss: 16.74755612019585\n"
     ]
    }
   ],
   "source": [
    "labels = [1, 2]\n",
    "test_predictions = sigmoid(np.dot(X_test_scaled, weights) + bias)\n",
    "test_predictions = (test_predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy and log loss on the test data\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "logloss = log_loss(y_test, test_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Log Loss: {logloss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e605e",
   "metadata": {},
   "source": [
    "## 9. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989cad21",
   "metadata": {},
   "source": [
    "### 9.1. Hyperparameter tuning using Grid Search CV and Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97ffb11c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Accuracy: 0.8424242424242424\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50],\n",
    "    'max_depth': [20],\n",
    "    'min_samples_split': [5]\n",
    "}\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by Grid Search\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the test data\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "test_predictions = best_rf_classifier.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435c245a",
   "metadata": {},
   "source": [
    "### From hyperparameter tuning using Grid Search CV and Random Forest Classifier we get slighlty better accuracy than the accuracy without tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a597726",
   "metadata": {},
   "source": [
    "### 9.2. Hyperparameter tuning using Grid search CV and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b95ded20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6035b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression(penalty= None, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a365548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de5755be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.8222222222222222\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(logmodel, param_grid, cv=5, scoring='accuracy',error_score='raise', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best hyperparameters:',best_params)\n",
    "best_model = grid_search.best_estimator_\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7357699c",
   "metadata": {},
   "source": [
    "### From hyperparameter tuning using Grid Search CV and Logistic Regression we get slighlty less accuracy than the accuracy without tuning. So, this model is not suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb380f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
